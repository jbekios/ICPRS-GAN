{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1-5X9OUkA-C2Ih1gOS9Jd7GmkTWUEpDg1)\n",
    "\n",
    "#  _Deep learning_ : GAN (Generative Adversarial Nets)\n",
    "   \n",
    "<center>\n",
    "    <img src='images/ladron-gan.png'style=\"width: 600px;\">\n",
    "    <sub><sup>https://dzone.com/articles/working-principles-of-generative-adversarial-netwo</sup></sub> \n",
    "</center>\n",
    "\n",
    "**Profesor**: Dr. Juan Bekios Calfa - **ICPRS 2021**\n",
    "\n",
    "<sub><sup>Tutorial: GANS. Sensio Artificial Intelligence [link](https://sensioai.com/blog/051_gans)</sup></sub> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "GANs (_generative adversarial networks_) es una arquitectura de red neuronal propuesta en 2014 por Ian Goodfellow y otros con el objetivo de obtener modelos capaces de generar datos sintéticos realistas, principalmente imágenes. \n",
    "\n",
    "Pese a la simplicidad de la idea original, se tardó varios años en superar varias de las dificultades que presenta su entrenamiento. Hoy en día, sin embargo, se utilizan para obtener resultados espectaculares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitectura\n",
    "\n",
    "La arquitectura básica de las GANs está formada por dos redes neuronales:\n",
    "\n",
    "* **El generador**: recibe a la entrada valores aleatorios (normalmente obtenidos de una distribución de tipo gausiana) y da a la salida una imagen. Puedes ver la entrada aleatoria como una representación latente (o codificación) de la imagen generada.\n",
    "* **El discriminador**: recibe a la entrada una imagen (real o generada por el generador) y tiene que decidir si bien la imagen es real o falsa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitectura\n",
    "\n",
    "<center>\n",
    "    <img src='images/gan-arq-animada.gif'style=\"width: 1000px;\">\n",
    "</center>\n",
    "\n",
    "<sub><sup>https://anderfernandez.com/blog/como-crear-una-red-generativa-antagonica-gan-en-python/</sup></sub> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Para poder entrenar una GAN:\n",
    "\n",
    "* En una **primera fase**, entrenamos el discriminador. En cada iteración, le daremos un batch compuesto de imágenes reales obtenidas del dataset e imágenes falsas generadas por el generador. Definiremos un conjunto de etiquetas a 0 para las imágenes falsas y 1 para las reales. Entonces, optimizaremos el discriminador (utilizando una función de pérdida de tipo binary cross-entropy mejorando así sus capacidades de distinguir imágenes falsas de reales.\n",
    "* En la **segunda fase**, entrenamos el generador. En cada iteración, le daremos un batch compuesto de ruido aleatorio para que genere imágenes. Estas imágenes son introducidas en el discriminador, cuyas salidas (etiquetas real/falso) son comparadas con un conjunto de etiquetas definidas como reales. Entonces, optimizaremos el generador (utilizando de nuevo la misma función de pérdida) de manera que el generador actualizará sus pesos para generar imágenes que engañen al discriminador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GAN simple\n",
    "\n",
    "Vamos a ver cómo podemos implementar esta arquitectura y proceso de entrenamiento con la implementación de una GAN muy simple para generar imágenes del _dataset Fashion MNIST_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar el conjunto de entrenamiento\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "\n",
    "classes = (\"t-shirt\", \"trousers\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, trainset):\n",
    "    self.imgs = torch.tensor([np.array(i[0]).flatten() / 255. for i in trainset], dtype=torch.float, device=device)\n",
    "    self.labels = torch.tensor([i[1] for i in trainset], dtype=torch.long, device=device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    return self.imgs[ix], self.labels[ix]\n",
    "\n",
    "train = Dataset(trainset)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "img.shape, img.dtype, img.max(), img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "\n",
    "imgs, labels = next(iter(dataloader))\n",
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "La base de datos está formado por **60000 imágenes** de baja resolución (**28 x 28 píxeles**, en blanco y negro) y contiene 10 tipos prendas de ropa (camisetas, pantalones, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r, c = 2, 9\n",
    "plt.figure(figsize=(c*3, r*3))\n",
    "for row in range(r):\n",
    "    for col in range(c):\n",
    "        index = c*row + col\n",
    "        plt.subplot(r, c, index + 1)\n",
    "        ix = random.randint(0, len(train)-1)\n",
    "        img, label = train[ix]\n",
    "        plt.imshow(img.reshape(28,28).cpu(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(classes[label.item()])\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementación GAN simple\n",
    "\n",
    "El objetivo es entrenar una GAN que sea capaz de generar imágenes similares a las que tenemos en la base de datos a partir de valores aleatorios (ruido). \n",
    "\n",
    "Se implementará **un generador** y **un discriminador**. Para esta implementación simple usaremos la misma arquitectura para ambas redes, un **Perceptrón Multicapa (MLP)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def block(n_in, n_out):\n",
    "  return nn.Sequential(\n",
    "      nn.Linear(n_in, n_out),\n",
    "      nn.ReLU(inplace=True)\n",
    "  )\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__()\n",
    "    self.input_size = input_size\n",
    "    self.fc1 = block(input_size, 150)\n",
    "    self.fc2 = block(150, 100)\n",
    "    self.fc3 = nn.Linear(100, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitectura\n",
    "\n",
    "La **red neuronal multicapa** está formado por 3 capas lineales (cada capa seguida de una activación relu). En función del número de entradas y salidas definiremos las diferentes redes. Por ejemplo, el generador recibirá un vector con 30 valores aleatorios y nos dará a la salida un vector de 28 x 28 valores (igual que las imágenes del dataset).\n",
    "\n",
    "### Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_in, n_out = 30, 28*28\n",
    "generator = MLP(n_in, n_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generador inicializado\n",
    "\n",
    "Como los pesos son aleatorios y no han sido entrenados. Si probamos con una **entrada aleatoria** la **salida esperada** será una **imagen con ruido**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Estimación de la imagen con 64 ejemplos aleatorios de entrada de 30 atributos\n",
    "output = generator(torch.randn(64, 30))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Imagen obtenido por el generador sin inicializar\n",
    "plt.imshow(output[40].reshape(28,28).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminador\n",
    "\n",
    "Recibirá a la entrada una imagen (28 x 28 valores) y a la salida nos dará una clasificación binaria (real o falso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Red discriminadora con un una entrada de 28*28 y un valor clase de salida\n",
    "discriminator = MLP(28*28, 1)\n",
    "output = discriminator(torch.randn(64, 28*28))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenando ambas redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# -- No corre --\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "def fit(g, d, dataloader, epochs=30, crit=None):\n",
    "  g.to(device)\n",
    "  d.to(device)\n",
    "  g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
    "  d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
    "  crit = nn.BCEWithLogitsLoss() if crit == None else crit\n",
    "  g_loss, d_loss = [], []\n",
    "  mb = master_bar(range(1, epochs+1))\n",
    "  hist = {'g_loss': [], 'd_loss': []}\n",
    "  for epoch in mb:\n",
    "    for X, y in progress_bar(dataloader, parent=mb):\n",
    "      #X, y = X.to(device), y.to(device)  \n",
    "      # entrenamos el discriminador\n",
    "      g.eval()\n",
    "      d.train()\n",
    "      #   generamos un batch de imágenes falsas\n",
    "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
    "      genenerated_images = g(noise)\n",
    "      #   Preparamos la entrada para el discriminador\n",
    "      d_input = torch.cat([genenerated_images, X.view(X.size(0), -1)])\n",
    "      print(X.view(X.size(0), -1))\n",
    "      #   gorund truth para el discriminator\n",
    "      d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -- No corre --\n",
    "      #   optimización\n",
    "      d_optimizer.zero_grad()\n",
    "      d_output = d(d_input)\n",
    "      d_l = crit(d_output, d_gt)\n",
    "      d_l.backward()\n",
    "      d_optimizer.step()\n",
    "      d_loss.append(d_l.item())\n",
    "      # entrenamos el generador\n",
    "      g.train()\n",
    "      d.eval()\n",
    "      #   generamos un batch de imágenes falsas\n",
    "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
    "      genenerated_images = g(noise)\n",
    "      #   salidas del discriminador\n",
    "      d_output = d(genenerated_images)\n",
    "      #   gorund truth para el generator\n",
    "      g_gt = torch.ones(X.size(0)).view(-1,1).to(device)\n",
    "      #   optimización\n",
    "      g_optimizer.zero_grad()\n",
    "      g_l = crit(d_output, g_gt)\n",
    "      g_l.backward()\n",
    "      g_optimizer.step()\n",
    "      g_loss.append(g_l.item())\n",
    "      # logs\n",
    "      mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
    "    mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
    "    hist['g_loss'].append(np.mean(g_loss))    \n",
    "    hist['d_loss'].append(np.mean(d_loss))\n",
    "  return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "def fit(g, d, dataloader, epochs=30, crit=None):\n",
    "  g.to(device)\n",
    "  d.to(device)\n",
    "  g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
    "  d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
    "  crit = nn.BCEWithLogitsLoss() if crit == None else crit\n",
    "  g_loss, d_loss = [], []\n",
    "  mb = master_bar(range(1, epochs+1))\n",
    "  hist = {'g_loss': [], 'd_loss': []}\n",
    "  for epoch in mb:\n",
    "    for X, y in progress_bar(dataloader, parent=mb):\n",
    "      #X, y = X.to(device), y.to(device)  \n",
    "      # entrenamos el discriminador\n",
    "      g.eval()\n",
    "      d.train()\n",
    "      #   generamos un batch de imágenes falsas\n",
    "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
    "      genenerated_images = g(noise)\n",
    "      #   Preparamos la entrada para el discriminador\n",
    "      d_input = torch.cat([genenerated_images, X.view(X.size(0), -1)])\n",
    "      #   gorund truth para el discriminator\n",
    "      d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1,1).to(device)\n",
    "      #   optimización\n",
    "      d_optimizer.zero_grad()\n",
    "      d_output = d(d_input)\n",
    "      d_l = crit(d_output, d_gt)\n",
    "      d_l.backward()\n",
    "      d_optimizer.step()\n",
    "      d_loss.append(d_l.item())\n",
    "      # entrenamos el generador\n",
    "      g.train()\n",
    "      d.eval()\n",
    "      #   generamos un batch de imágenes falsas\n",
    "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
    "      genenerated_images = g(noise)\n",
    "      #   salidas del discriminador\n",
    "      d_output = d(genenerated_images)\n",
    "      #   gorund truth para el generator\n",
    "      g_gt = torch.ones(X.size(0)).view(-1,1).to(device)\n",
    "      #   optimización\n",
    "      g_optimizer.zero_grad()\n",
    "      g_l = crit(d_output, g_gt)\n",
    "      g_l.backward()\n",
    "      g_optimizer.step()\n",
    "      g_loss.append(g_l.item())\n",
    "      # logs\n",
    "      mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
    "    mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
    "    hist['g_loss'].append(np.mean(g_loss))    \n",
    "    hist['d_loss'].append(np.mean(d_loss))\n",
    "  return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejecutamos el entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hist = fit(generator, discriminator, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualización de las pérdidas en el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(hist)\n",
    "df.plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probando generador entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "  noise = torch.randn((10, generator.input_size)).to(device)\n",
    "  generated_images = generator(noise)\n",
    "  fig, axs = plt.subplots(2,5,figsize=(15,5))\n",
    "  i = 0\n",
    "  for ax in axs:\n",
    "    for _ax in ax:\n",
    "      img = generated_images[i].view(28,28).cpu()\n",
    "      _ax.imshow(img, cmap='gray')\n",
    "      i+=1\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DCGANs\n",
    "\n",
    "Podemos usar **DCGANs** (_deep convolutional GANs_) para obtener mejores generadores utilizando redes convolucionales. En este caso, necesitaremos arquitecturas diferentes para generador y discriminador.\n",
    "\n",
    "<center>\n",
    "    <img src='images/dcgan.png'style=\"width: 900px;\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitecura\n",
    "\n",
    "El **generador** recibirá un vector de 100 valores aleatorios y después aplicaremos varias capas de convoluciones transpuestas (que aumentarán el tamaño de los mapas de caracterísitcas, como vimos en las redes para segmentación) hasta obtener la imagen generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.input_size = 100\n",
    "    self.inp = nn.Sequential(\n",
    "        nn.Linear(self.input_size, 7*7*128),\n",
    "        nn.BatchNorm1d(7*7*128),\n",
    "    )\n",
    "    self.main = nn.Sequential(\n",
    "        nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1, bias=False),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.inp(x)\n",
    "    x = x.view(-1, 128, 7, 7)\n",
    "    x = self.main(x)\n",
    "    x = x.view(x.size(0), 28*28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Configurando el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "output = generator(torch.randn(64, 100))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Al final del generador usamos una activación **tanh**, que dará valores entre -1 y 1. Por este motivo tenemos que **re-normalizar nuestras imágenes en el dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, trainset):\n",
    "    self.imgs = torch.tensor([np.array(i[0]).flatten() / 255. for i in trainset], dtype=torch.float, device=device)\n",
    "    self.imgs = self.imgs * 2. - 1.\n",
    "    self.labels = torch.tensor([i[1] for i in trainset], dtype=torch.long, device=device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    return self.imgs[ix], self.labels[ix]\n",
    "\n",
    "train = Dataset(trainset)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "img.shape, img.dtype, img.max(), img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "\n",
    "imgs, labels = next(iter(dataloader))\n",
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminador\n",
    "\n",
    "Usaremos CNN típica como las que conocemos cuando trabajamos en clasificación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, 4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(True),\n",
    "        nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(True)\n",
    "    )\n",
    "    self.out = nn.Sequential(\n",
    "        nn.Linear(128*7*7, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    # esperamos vectores a la entrada de 28*28\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    x = self.main(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "output = discriminator(torch.randn(64, 28*28))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizamos la pérdida del modelo para el generador y el discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hist)\n",
    "df.plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Revisamos los modelos generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "  noise = torch.randn((10, generator.input_size)).to(device)\n",
    "  generated_images = generator(noise)\n",
    "  fig, axs = plt.subplots(2,5,figsize=(15,5))\n",
    "  i = 0\n",
    "  for ax in axs:\n",
    "    for _ax in ax:\n",
    "      img = generated_images[i].view(28,28).cpu()\n",
    "      _ax.imshow(img, cmap='gray')\n",
    "      i+=1\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ejemplo real\n",
    "\n",
    "* Generador de caras: https://thispersondoesnotexist.com/\n",
    "* Generador de gatos: https://thiscatdoesnotexist.com/\n",
    "* Generador de arte: https://thisartworkdoesnotexist.com\n",
    "\n",
    "<center>\n",
    "    <img src='images/fake-face.jpeg'style=\"width: 500px;\">\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
